{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pip install --no-cache-dir --ignore-installed numpy pandas bs4 nltk scikit-learn matplotlib graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#adapted from:\n",
    "#https://github.com/sahilee26/IMDB-Movie-Reviews-Sentiment-Analysis/blob/master/Bag-of-words-random-forest.ipynb\n",
    "#https://github.com/shiaoligreen/practical-data-science/tree/master/Bag%20of%20Words%20Meets%20Bags%20of%20Popcorn\n",
    "\n",
    "# Load packages\n",
    "\n",
    "#Generic tools\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "#Data pre-preprocessing\n",
    "import pandas as pd  \n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltkstopwords\n",
    "import nltk.data\n",
    "\n",
    "#Data split and featurization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Random forest classifier and evaluation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Random forest visualization\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "#Multilayer Perceptron classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv(\"data/labeledTrainData.tsv\", \n",
    "                    header=0, delimiter=\"\\t\", \n",
    "                    quoting=3)\n",
    "\n",
    "test = pd.read_csv(\"data/testData.tsv\", \n",
    "                   header=0, delimiter=\"\\t\",\n",
    "                   quoting=3 )\n",
    "\n",
    "unlabeled_train = pd.read_csv(\"data/unlabeledTrainData.tsv\", header=0, \n",
    "                              delimiter=\"\\t\", quoting=3 )\n",
    "\n",
    "# Split data to train and test partitions\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.drop(columns=['sentiment']), \n",
    "                                                    train.sentiment, test_size=0.2)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download text datasets, including stop words\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords as nltkstopwords\n",
    "#print(nltkstopwords.words('english'))\n",
    "#print(nltkstopwords.words('german'))\n",
    "#print(nltkstopwords.words('chinese'))\n",
    "#print(nltkstopwords.words.__dir__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def review_to_words(review, string=True, remove_stopwords=False):\n",
    "    '''\n",
    "    Function to convert a document to a sequence of words, \n",
    "    optionally removing stop words.  \n",
    "    Returns a list of words.\n",
    "    '''\n",
    "    # Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    \n",
    "    # Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "    # Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    \n",
    "    # Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(nltkstopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    if string:\n",
    "        return \" \".join(words)\n",
    "    else:\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_bigrams(review, remove_stopwords=False, add_startend_tokens=True):\n",
    "    '''\n",
    "    Function to convert a document to a sequence of word bigrams,\n",
    "    optionally removing stop words.\n",
    "    Returns a list of bigrams.\n",
    "    '''\n",
    "    #E.g., [\"I\", \"liked\", \"this\" ,\"movie\"] -> [\"I liked\", \"liked this\", \"this movie\"]\n",
    "    #your code here     \n",
    "    \n",
    "    # Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    \n",
    "    # Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "    # Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    \n",
    "    # Optionally add START and END tokens (True by default)\n",
    "    if add_startend_tokens:\n",
    "        words = [\"START\"] + words + [\"END\"]\n",
    "        \n",
    "    # Optionally remove stop words (False by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(nltkstopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    \n",
    "    # Generate bigrams\n",
    "    bigrams = []\n",
    "    for i in range(len(words)-1):\n",
    "        bigrams.append(words[i] + \" \" + words[i+1])\n",
    "\n",
    "    return bigrams\n",
    "\n",
    "#print(review_to_bigrams([\"I\", \"liked\", \"this\", \"movie\"]))\n",
    "my_bigrams =review_to_bigrams(\"I liked this movie\")\n",
    "print(my_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Get list of reviews\n",
    "clean_train_reviews = [review_to_words(X_train[\"review\"][i], remove_stopwords=True) for i in range(len(X_train))]\n",
    "clean_test_reviews = [review_to_words(X_test[\"review\"][i], remove_stopwords=True) for i in range(len(X_test))]\n",
    "\n",
    "print(clean_train_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Get lists of reviews using the bigram function instead of the review_to_words function\n",
    "\n",
    "clean_train_bigram_reviews = [review_to_bigrams(X_train[\"review\"][i]) for i in range(len(X_train))]\n",
    "clean_test_bigram_reviews = [review_to_bigrams(X_test[\"review\"][i]) for i in range(len(X_test))]\n",
    "\n",
    "print(clean_train_bigram_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Initialize a bag of words  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None,   \n",
    "                             max_features = 5000) #vocabulary size defined here, sorted by frequency - e.g., 5k most common terms.  How does model performance change if you increase/decrease this value?\n",
    "\n",
    "# Fit transform the data\n",
    "train_feat = vectorizer.fit_transform(clean_train_reviews).toarray()\n",
    "test_feat = vectorizer.transform(clean_test_reviews).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Take a look at the vocabulary\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(vocab[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "def get_preds(test_feat, train_feat, y_test, y_train, model, title='Random Forest'):\n",
    "    print(\"Training model, this may take some time...\")\n",
    "    model.fit(train_feat, y_train)\n",
    "    \n",
    "    print(\"Evaluating model...\")\n",
    "    y_preds = model.predict(test_feat)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_preds)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    #fpr, tpr, _ = roc_curve(y_test, preds)\n",
    "    #roc_auc = auc(fpr, tpr)\n",
    "    #print('AUC:', roc_auc)\n",
    "    \n",
    "    #F1 doesn't matter because of class balance here\n",
    "    \n",
    "    # plot AUC\n",
    "    #plt.plot(fpr, tpr)\n",
    "    #plt.title(title)\n",
    "    #plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    #plt.xlabel('False Positive Rate')\n",
    "    #plt.ylabel('True Positive Rate')\n",
    "    #plt.show()\n",
    "    \n",
    "    return y_preds, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "preds_rf, model = get_preds(test_feat, train_feat, \n",
    "                  y_test, y_train, \n",
    "                  RandomForestClassifier(n_estimators = 100)) #How does performance changes if you increase/decrease the number of estimators (trees)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try train in LogisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rf, model = get_preds(test_feat, train_feat, \n",
    "                  y_test, y_train, \n",
    "                  LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rf, model = get_preds(test_feat, train_feat, \n",
    "                  y_test, y_train, \n",
    "                  LogisticRegression(penalty='l2', max_iter=500, C=0.1, random_state=42)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a list of models with different parameters\n",
    "models = [\n",
    "    LogisticRegression(penalty='l2', max_iter=500, C=0.1, random_state=42),\n",
    "    LogisticRegression(penalty='l2', max_iter=500, C=1, solver='liblinear', random_state=42),\n",
    "    LogisticRegression(penalty='l2', max_iter=500, C=1, class_weight='balanced', random_state=42),\n",
    "    LogisticRegression(penalty='l2', max_iter=1000, C=0.5, solver='saga', class_weight='balanced', random_state=42)\n",
    "]\n",
    "\n",
    "# Initialize variables to keep track of the best model and its score\n",
    "best_model = None\n",
    "best_score = 0\n",
    "\n",
    "# Iterate through the list of models\n",
    "for model in models:\n",
    "    # Fit the model on the training data\n",
    "    model.fit(train_feat, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    preds = model.predict(test_feat)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    score = accuracy_score(y_test, preds)\n",
    "    \n",
    "    # Check if this model is the best so far\n",
    "    if score > best_score:\n",
    "        best_model = model\n",
    "        best_score = score\n",
    "\n",
    "# Output the best model and its score\n",
    "print(f'Best Model: {best_model}')\n",
    "print(f'Best Accuracy: {best_score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear svm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rf, model = get_preds(test_feat, train_feat, \n",
    "                  y_test, y_train, \n",
    "                  SGDClassifier(loss='hinge',max_iter=500,random_state=42)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # visualize decision tree from classifier\n",
    "for i in range(10):\n",
    "    tree = model.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=vocab,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(preds_rf[0]) #first prediction for test item - model predicted positive sentiment\n",
    "print(test_feat[0]) #first test review\n",
    "print(clean_test_reviews[0])\n",
    "print(type(y_test))\n",
    "print(y_test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "print(\"Training MLP classifier... this may take some time\")\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,),random_state=1, max_iter=300, verbose=True).fit(train_feat, y_train)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = mlp_clf.score(test_feat, y_test)\n",
    "print(\"Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "print(\"Training deeper MLP classifier... this may take some time\")\n",
    "mlp_clf_deeper = MLPClassifier(hidden_layer_sizes=(500,250,500,),random_state=1, max_iter=300, verbose=True).fit(train_feat, y_train)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = mlp_clf_deeper.score(test_feat, y_test)\n",
    "print(\"Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "print(\"Training deeper MLP classifier... this may take some time\")\n",
    "mlp_clf_deeper = MLPClassifier(hidden_layer_sizes=(500,250,500,),random_state=1, max_iter=300, verbose=True).fit(train_feat, y_train)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
