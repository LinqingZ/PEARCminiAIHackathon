{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --no-cache-dir --ignore-installed numpy pandas bs4 nltk scikit-learn matplotlib graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#adapted from:\n",
    "#https://github.com/sahilee26/IMDB-Movie-Reviews-Sentiment-Analysis/blob/master/Bag-of-words-random-forest.ipynb\n",
    "#https://github.com/shiaoligreen/practical-data-science/tree/master/Bag%20of%20Words%20Meets%20Bags%20of%20Popcorn\n",
    "\n",
    "# Load packages\n",
    "\n",
    "#Generic tools\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "#Data pre-preprocessing\n",
    "import pandas as pd  \n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltkstopwords\n",
    "import nltk.data\n",
    "\n",
    "#Data split and featurization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Random forest classifier and evaluation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Random forest visualization\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "#Multilayer Perceptron classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv(\"data/labeledTrainData.tsv\", \n",
    "                    header=0, delimiter=\"\\t\", \n",
    "                    quoting=3)\n",
    "\n",
    "test = pd.read_csv(\"data/testData.tsv\", \n",
    "                   header=0, delimiter=\"\\t\",\n",
    "                   quoting=3 )\n",
    "\n",
    "unlabeled_train = pd.read_csv(\"data/unlabeledTrainData.tsv\", header=0, \n",
    "                              delimiter=\"\\t\", quoting=3 )\n",
    "\n",
    "# Split data to train and test partitions\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.drop(columns=['sentiment']), \n",
    "                                                    train.sentiment, test_size=0.2)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\xiuwen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download text datasets, including stop words\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords as nltkstopwords\n",
    "#print(nltkstopwords.words('english'))\n",
    "#print(nltkstopwords.words('german'))\n",
    "#print(nltkstopwords.words('chinese'))\n",
    "#print(nltkstopwords.words.__dir__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def review_to_words(review, string=True, remove_stopwords=False):\n",
    "    '''\n",
    "    Function to convert a document to a sequence of words, \n",
    "    optionally removing stop words.  \n",
    "    Returns a list of words.\n",
    "    '''\n",
    "    # Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    \n",
    "    # Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "    # Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    \n",
    "    # Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(nltkstopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    if string:\n",
    "        return \" \".join(words)\n",
    "    else:\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['START i', 'i liked', 'liked this', 'this movie', 'movie END']\n"
     ]
    }
   ],
   "source": [
    "def review_to_bigrams(review, remove_stopwords=False, add_startend_tokens=True):\n",
    "    '''\n",
    "    Function to convert a document to a sequence of word bigrams,\n",
    "    optionally removing stop words.\n",
    "    Returns a list of bigrams.\n",
    "    '''\n",
    "    #E.g., [\"I\", \"liked\", \"this\" ,\"movie\"] -> [\"I liked\", \"liked this\", \"this movie\"]\n",
    "    #your code here     \n",
    "    \n",
    "    # Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    \n",
    "    # Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "    # Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    \n",
    "    # Optionally add START and END tokens (True by default)\n",
    "    if add_startend_tokens:\n",
    "        words = [\"START\"] + words + [\"END\"]\n",
    "        \n",
    "    # Optionally remove stop words (False by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(nltkstopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    \n",
    "    # Generate bigrams\n",
    "    bigrams = []\n",
    "    for i in range(len(words)-1):\n",
    "        bigrams.append(words[i] + \" \" + words[i+1])\n",
    "\n",
    "    return bigrams\n",
    "\n",
    "#print(review_to_bigrams([\"I\", \"liked\", \"this\", \"movie\"]))\n",
    "my_bigrams =review_to_bigrams(\"I liked this movie\")\n",
    "print(my_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiuwen\\AppData\\Local\\Temp\\ipykernel_14340\\766223517.py:8: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  review_text = BeautifulSoup(review).get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "really shame films like never snag best picture nominations one simply winner far consistently hilarious comedy ever seen screenplay design impeccable mention incredible cast quote movie hours end watch\n"
     ]
    }
   ],
   "source": [
    "# Get list of reviews\n",
    "clean_train_reviews = [review_to_words(X_train[\"review\"][i], remove_stopwords=True) for i in range(len(X_train))]\n",
    "clean_test_reviews = [review_to_words(X_test[\"review\"][i], remove_stopwords=True) for i in range(len(X_test))]\n",
    "\n",
    "print(clean_train_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiuwen\\AppData\\Local\\Temp\\ipykernel_14340\\885493429.py:11: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  review_text = BeautifulSoup(review).get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['START it', 'it really', 'really is', 'is a', 'a shame', 'shame that', 'that films', 'films like', 'like this', 'this never', 'never snag', 'snag best', 'best picture', 'picture nominations', 'nominations because', 'because this', 'this one', 'one is', 'is simply', 'simply a', 'a winner', 'winner this', 'this is', 'is by', 'by far', 'far the', 'the most', 'most consistently', 'consistently hilarious', 'hilarious comedy', 'comedy i', 'i have', 'have ever', 'ever seen', 'seen its', 'its screenplay', 'screenplay and', 'and design', 'design are', 'are impeccable', 'impeccable not', 'not to', 'to mention', 'mention the', 'the incredible', 'incredible cast', 'cast i', 'i can', 'can quote', 'quote this', 'this movie', 'movie for', 'for hours', 'hours on', 'on end', 'end watch', 'watch it', 'it END']\n"
     ]
    }
   ],
   "source": [
    "# Get lists of reviews using the bigram function instead of the review_to_words function\n",
    "\n",
    "clean_train_bigram_reviews = [review_to_bigrams(X_train[\"review\"][i]) for i in range(len(X_train))]\n",
    "clean_test_bigram_reviews = [review_to_bigrams(X_test[\"review\"][i]) for i in range(len(X_test))]\n",
    "\n",
    "print(clean_train_bigram_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Initialize a bag of words  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                             tokenizer = None,    \n",
    "                             preprocessor = None, \n",
    "                             stop_words = None,   \n",
    "                             max_features = 5000) #vocabulary size defined here, sorted by frequency - e.g., 5k most common terms.  How does model performance change if you increase/decrease this value?\n",
    "\n",
    "# Fit transform the data\n",
    "train_feat = vectorizer.fit_transform(clean_train_reviews).toarray()\n",
    "test_feat = vectorizer.transform(clean_test_reviews).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 5000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandoned' 'abc' 'abilities' 'ability' 'able' 'abraham' 'abrupt'\n",
      " 'absence' 'absent' 'absolute' 'absolutely' 'absurd' 'abuse' 'abused'\n",
      " 'abusive' 'abysmal' 'academy' 'accent' 'accents' 'accept' 'acceptable'\n",
      " 'accepted' 'access' 'accident' 'accidentally' 'accompanied' 'accomplish'\n",
      " 'accomplished' 'according' 'account' 'accuracy' 'accurate' 'accused'\n",
      " 'achieve' 'achieved' 'achievement' 'acid' 'across' 'act' 'acted' 'acting'\n",
      " 'action' 'actions' 'actor' 'actors' 'actress' 'actresses' 'acts' 'actual'\n",
      " 'actually' 'ad' 'adam' 'adams' 'adaptation' 'adaptations' 'adapted' 'add'\n",
      " 'added' 'addicted' 'adding' 'addition' 'adds' 'adequate' 'admire' 'admit'\n",
      " 'admittedly' 'adolescent' 'adopted' 'adorable' 'adult' 'adults' 'advance'\n",
      " 'advanced' 'advantage' 'adventure' 'adventures' 'advertising' 'advice'\n",
      " 'advise' 'affair' 'affect' 'affected' 'afford' 'aforementioned' 'afraid'\n",
      " 'africa' 'african' 'afternoon' 'afterwards' 'age' 'aged' 'agent' 'ages'\n",
      " 'aging' 'ago' 'agree' 'agreed' 'agrees' 'ah' 'ahead']\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the vocabulary\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "print(vocab[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "def get_preds(test_feat, train_feat, y_test, y_train, model, title='Random Forest'):\n",
    "    print(\"Training model, this may take some time...\")\n",
    "    model.fit(train_feat, y_train)\n",
    "    \n",
    "    print(\"Evaluating model...\")\n",
    "    y_preds = model.predict(test_feat)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_preds)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    #fpr, tpr, _ = roc_curve(y_test, preds)\n",
    "    #roc_auc = auc(fpr, tpr)\n",
    "    #print('AUC:', roc_auc)\n",
    "    \n",
    "    #F1 doesn't matter because of class balance here\n",
    "    \n",
    "    # plot AUC\n",
    "    #plt.plot(fpr, tpr)\n",
    "    #plt.title(title)\n",
    "    #plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    #plt.xlabel('False Positive Rate')\n",
    "    #plt.ylabel('True Positive Rate')\n",
    "    #plt.show()\n",
    "    \n",
    "    return y_preds, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model, this may take some time...\n",
      "Evaluating model...\n",
      "Accuracy: 0.8358\n"
     ]
    }
   ],
   "source": [
    "preds_rf, model = get_preds(test_feat, train_feat, \n",
    "                  y_test, y_train, \n",
    "                  RandomForestClassifier(n_estimators = 100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try LogisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model, this may take some time...\n",
      "Evaluating model...\n",
      "Accuracy: 0.8548\n"
     ]
    }
   ],
   "source": [
    "preds_rf, model = get_preds(test_feat, train_feat, \n",
    "                  y_test, y_train, \n",
    "                  LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model, this may take some time...\n",
      "Evaluating model...\n",
      "Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "preds_rf, model = get_preds(test_feat, train_feat, \n",
    "                  y_test, y_train, \n",
    "                  LogisticRegression(penalty='l2', max_iter=500, C=0.1, random_state=42)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model, this may take some time...\n",
      "Evaluating model...\n",
      "Accuracy: 0.855\n"
     ]
    }
   ],
   "source": [
    "preds_rf, model = get_preds(test_feat, train_feat, \n",
    "                  y_test, y_train, \n",
    "                  LogisticRegression(penalty='l2', max_iter=500, C=1, class_weight='balanced', random_state=42)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model, this may take some time...\n",
      "Evaluating model...\n",
      "Accuracy: 0.8544\n"
     ]
    }
   ],
   "source": [
    "preds_rf, model = get_preds(test_feat, train_feat, \n",
    "                  y_test, y_train, \n",
    "                  LogisticRegression(penalty='l2', max_iter=500, C=1, solver='liblinear', random_state=42)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model, this may take some time...\n"
     ]
    }
   ],
   "source": [
    "preds_rf, model = get_preds(test_feat, train_feat, \n",
    "                  y_test, y_train, \n",
    "                  LogisticRegression(penalty='l2', max_iter=1000, C=0.5, solver='saga', class_weight='balanced', random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a list of models with different parameters\n",
    "models = [\n",
    "    LogisticRegression(penalty='l2', max_iter=500, C=0.1, random_state=42),\n",
    "    LogisticRegression(penalty='l2', max_iter=500, C=1, solver='liblinear', random_state=42),\n",
    "    LogisticRegression(penalty='l2', max_iter=500, C=1, class_weight='balanced', random_state=42),\n",
    "    LogisticRegression(penalty='l2', max_iter=1000, C=0.5, solver='saga', class_weight='balanced', random_state=42)\n",
    "]\n",
    "\n",
    "# Initialize variables to keep track of the best model and its score\n",
    "best_model = None\n",
    "best_score = 0\n",
    "\n",
    "# Iterate through the list of models\n",
    "for model in models:\n",
    "    # Fit the model on the training data\n",
    "    model.fit(train_feat, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    preds = model.predict(test_feat)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    score = accuracy_score(y_test, preds)\n",
    "\n",
    "    print(f'Model: {model}')\n",
    "    print(f'Accuracy: {score}')\n",
    "    \n",
    "    # Check if this model is the best so far\n",
    "    if score > best_score:\n",
    "        best_model = model\n",
    "        best_score = score\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# Output the best model and its score\n",
    "print(f'Best Model: {best_model}')\n",
    "print(f'Best Accuracy: {best_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rf, model = get_preds(test_feat, train_feat, \n",
    "                  y_test, y_train, \n",
    "                  SGDClassifier(loss='hinge',max_iter=500,random_state=42)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # visualize decision tree from classifier\n",
    "for i in range(10):\n",
    "    tree = model.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=vocab,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(preds_rf[0]) #first prediction for test item - model predicted positive sentiment\n",
    "print(test_feat[0]) #first test review\n",
    "print(clean_test_reviews[0])\n",
    "print(type(y_test))\n",
    "print(y_test.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "print(\"Training MLP classifier... this may take some time\")\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,),random_state=1, max_iter=300, verbose=True).fit(train_feat, y_train)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = mlp_clf.score(test_feat, y_test)\n",
    "print(\"Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "print(\"Training deeper MLP classifier... this may take some time\")\n",
    "mlp_clf_deeper = MLPClassifier(hidden_layer_sizes=(500,250,500,),random_state=1, max_iter=300, verbose=True).fit(train_feat, y_train)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = mlp_clf_deeper.score(test_feat, y_test)\n",
    "print(\"Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "print(\"Training deeper MLP classifier... this may take some time\")\n",
    "mlp_clf_deeper = MLPClassifier(hidden_layer_sizes=(500,250,500,),random_state=1, max_iter=300, verbose=True).fit(train_feat, y_train)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
